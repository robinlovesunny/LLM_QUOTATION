#!/usr/bin/env python3
"""
åŸºäº qwen-plus çš„ç™¾ç‚¼æ¨¡å‹æ•°æ®è§£æå™¨ V2
æ”¹è¿›ï¼šæ”¯æŒé˜¶æ¢¯è®¡ä»·è¡¨æ ¼çš„å…³è”è§£æ
"""

import os
import json
import re
from typing import List, Dict, Optional, Tuple
from bs4 import BeautifulSoup, Tag
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()


class LLMModelParserV2:
    """ä½¿ç”¨ qwen-plus è§£ææ¨¡å‹æ•°æ®ï¼Œæ”¯æŒé˜¶æ¢¯è®¡ä»·"""
    
    def __init__(self):
        self.client = OpenAI(
            api_key=os.getenv("DASHSCOPE_API_KEY"),
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
        )
        self.model = "qwen-plus"
    
    def parse_html_file(self, html_path: str) -> Dict:
        """è§£æHTMLæ–‡ä»¶"""
        print("=" * 60)
        print("ğŸ¤– å¼€å§‹ä½¿ç”¨ qwen-plus è§£æç™¾ç‚¼æ¨¡å‹æ•°æ® (V2 - æ”¯æŒé˜¶æ¢¯è®¡ä»·)")
        print("=" * 60)
        
        with open(html_path, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # æ‰¾å‡ºæ‰€æœ‰è¡¨æ ¼åŠå…¶ä¸Šä¸‹æ–‡å…³ç³»
        table_groups = self._find_model_and_pricing_tables(soup)
        print(f"\nğŸ“Š æ‰¾åˆ° {len(table_groups)} ç»„æ¨¡å‹+é˜¶æ¢¯è®¡ä»·è¡¨æ ¼")
        
        all_models = []
        total_input_tokens = 0
        total_output_tokens = 0
        
        for i, group in enumerate(table_groups):
            print(f"\nğŸ”„ å¤„ç†è¡¨æ ¼ç»„ {i+1}/{len(table_groups)}...")
            print(f"   æ¨¡å‹: {group['models'][:3]}...")
            
            models, usage = self._parse_table_group_with_llm(group)
            if models:
                all_models.extend(models)
                total_input_tokens += usage.get('input', 0)
                total_output_tokens += usage.get('output', 0)
                print(f"   âœ… æå–åˆ° {len(models)} ä¸ªæ¨¡å‹")
        
        # å»é‡
        unique_models = self._deduplicate_models(all_models)
        
        result = {
            "source": "bailian_llm_v2_parsed",
            "parser": "qwen-plus",
            "model_count": len(unique_models),
            "models": unique_models,
            "token_usage": {
                "input_tokens": total_input_tokens,
                "output_tokens": total_output_tokens,
                "total_tokens": total_input_tokens + total_output_tokens
            }
        }
        
        # ä¿å­˜ç»“æœ
        output_path = html_path.replace('.html', '_llm_v2.json')
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… LLM V2 è§£æå®Œæˆ!")
        print(f"   - æ¨¡å‹æ•°é‡: {len(unique_models)}")
        print(f"   - Tokenæ¶ˆè€—: è¾“å…¥={total_input_tokens}, è¾“å‡º={total_output_tokens}")
        print(f"   - è¾“å‡ºæ–‡ä»¶: {output_path}")
        
        return result
    
    def _find_model_and_pricing_tables(self, soup: BeautifulSoup) -> List[Dict]:
        """
        æ‰¾å‡ºæ¨¡å‹è¡¨æ ¼åŠå…¶å…³è”çš„é˜¶æ¢¯è®¡ä»·è¡¨æ ¼
        ç»“æ„ï¼šæ¨¡å‹è¡¨æ ¼ -> æè¿°æ–‡å­— -> é˜¶æ¢¯è®¡ä»·è¡¨æ ¼
        """
        groups = []
        tables = soup.find_all('table')
        
        for i, table in enumerate(tables):
            table_text = self._extract_table_text(table)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ¨¡å‹è¡¨æ ¼ï¼ˆåŒ…å«"é˜¶æ¢¯è®¡ä»·"å¼•ç”¨ï¼‰
            if 'é˜¶æ¢¯è®¡ä»·' in table_text and 'è¯·å‚è§' in table_text:
                # æå–æ¨¡å‹åç§°
                models = self._extract_model_names_from_table(table)
                if not models:
                    continue
                
                # æŸ¥æ‰¾ç´§éšå…¶åçš„é˜¶æ¢¯è®¡ä»·è¡¨æ ¼
                tiered_pricing_table = self._find_next_pricing_table(table)
                
                if tiered_pricing_table:
                    tiered_text = self._extract_table_text(tiered_pricing_table)
                    groups.append({
                        'models': models,
                        'model_table_text': table_text,
                        'tiered_pricing_text': tiered_text,
                        'has_tiered_pricing': True
                    })
        
        return groups
    
    def _extract_model_names_from_table(self, table: Tag) -> List[str]:
        """ä»è¡¨æ ¼ä¸­æå–æ¨¡å‹åç§°"""
        models = []
        rows = table.find_all('tr')
        
        # å¸¸è§æ¨¡å‹åç§°æ¨¡å¼
        model_patterns = [
            r'\b(qwen[0-9a-z\-\.]+)\b',
            r'\b(deepseek-[a-z0-9\-\.]+)\b',
            r'\b(glm-[0-9a-z\-\.]+)\b',
            r'\b(llama-[0-9a-z\-\.]+)\b',
        ]
        
        for row in rows:
            cells = row.find_all(['td', 'th'])
            for cell in cells:
                text = cell.get_text()
                for pattern in model_patterns:
                    matches = re.findall(pattern, text, re.IGNORECASE)
                    models.extend([m.lower() for m in matches])
        
        return list(set(models))
    
    def _find_next_pricing_table(self, model_table: Tag) -> Optional[Tag]:
        """æŸ¥æ‰¾æ¨¡å‹è¡¨æ ¼ä¹‹åçš„é˜¶æ¢¯è®¡ä»·è¡¨æ ¼"""
        # è·å–å½“å‰è¡¨æ ¼ä¹‹åçš„å…„å¼Ÿå…ƒç´ 
        current = model_table.next_sibling
        
        # æœ€å¤šå‘åæŸ¥æ‰¾5ä¸ªå…ƒç´ 
        for _ in range(10):
            if current is None:
                break
            
            # å¦‚æœæ˜¯è¡¨æ ¼ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯é˜¶æ¢¯è®¡ä»·è¡¨æ ¼
            if isinstance(current, Tag) and current.name == 'table':
                table_text = self._extract_table_text(current)
                # é˜¶æ¢¯è®¡ä»·è¡¨æ ¼ç‰¹å¾ï¼šåŒ…å«TokenåŒºé—´å’Œä»·æ ¼
                if ('Token' in table_text and 
                    ('â‰¤' in table_text or '<' in table_text) and
                    'å…ƒ' in table_text):
                    return current
            
            # å¦‚æœé‡åˆ°æ®µè½ï¼Œæ£€æŸ¥æ˜¯å¦åŒ…å«"é˜¶æ¢¯è®¡è´¹"æè¿°
            if isinstance(current, Tag) and current.name == 'p':
                text = current.get_text()
                if 'é˜¶æ¢¯è®¡' in text:
                    # ç»§ç»­æŸ¥æ‰¾ä¸‹ä¸€ä¸ªè¡¨æ ¼
                    pass
            
            current = current.next_sibling
        
        return None
    
    def _extract_table_text(self, table: Tag) -> str:
        """å°†è¡¨æ ¼è½¬æ¢ä¸ºç»“æ„åŒ–æ–‡æœ¬"""
        rows = table.find_all('tr')
        if not rows:
            return ""
        
        lines = []
        for row in rows:
            cells = row.find_all(['th', 'td'])
            cell_texts = [cell.get_text(strip=True) for cell in cells]
            if any(cell_texts):
                lines.append(' | '.join(cell_texts))
        
        return '\n'.join(lines)
    
    def _parse_table_group_with_llm(self, group: Dict) -> Tuple[List[Dict], Dict]:
        """ä½¿ç”¨LLMè§£æè¡¨æ ¼ç»„ï¼ˆæ¨¡å‹+é˜¶æ¢¯è®¡ä»·ï¼‰"""
        
        prompt = f"""è¯·ä»ä»¥ä¸‹æ•°æ®ä¸­æå–LLMæ¨¡å‹å®šä»·ä¿¡æ¯ã€‚

## æ¨¡å‹è¡¨æ ¼
{group['model_table_text'][:4000]}

## é˜¶æ¢¯è®¡ä»·è¡¨æ ¼
{group['tiered_pricing_text'][:2000]}

## è¦æ±‚
1. ä¸ºæ¯ä¸ªæ¨¡å‹ï¼ˆ{', '.join(group['models'][:5])}ç­‰ï¼‰åˆ›å»ºå®Œæ•´çš„æ•°æ®æ¡ç›®
2. é˜¶æ¢¯è®¡ä»·è¡¨æ ¼ä¸­çš„ä»·æ ¼é€‚ç”¨äºä¸Šé¢æ‰€æœ‰æ¨¡å‹
3. æŒ‰ç…§ä¸Šä¸‹æ–‡çª—å£åˆ†æ®µå»ºæ¨¡tiered_pricingï¼š
   - æ¯ä¸ªä»·æ ¼æ®µåŒ…å«ï¼štoken_rangeï¼ˆå¦‚"0-128K"ï¼‰ã€input_priceã€output_price
4. model_idå¿…é¡»æ˜¯æ ‡å‡†APIåç§°ï¼ˆå¦‚qwen-plus, qwen-maxï¼‰

## è¾“å‡ºæ ¼å¼ï¼ˆJSONæ•°ç»„ï¼‰
```json
[{{
  "model_id": "qwen-plus",
  "model_name": "é€šä¹‰åƒé—®Plus",
  "vendor": "aliyun",
  "category": "text_generation",
  "specs": {{"max_context_length": 1000000, "max_input_tokens": 995904}},
  "tiered_pricing": [
    {{"token_range": "0-128K", "input_price": 0.008, "output_price": 0.002}},
    {{"token_range": "128K-256K", "input_price": 0.016, "output_price": 0.004}}
  ]
}}]
```

åªè¿”å›JSONæ•°ç»„ï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯æ•°æ®æå–ä¸“å®¶ï¼Œæ“…é•¿ä»å¤æ‚è¡¨æ ¼ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯ã€‚åªè¿”å›JSONã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=4000
            )
            
            content = response.choices[0].message.content
            usage = {
                'input': response.usage.prompt_tokens,
                'output': response.usage.completion_tokens
            }
            
            models = self._extract_json_from_response(content)
            return models, usage
            
        except Exception as e:
            print(f"   âŒ LLMè°ƒç”¨å¤±è´¥: {e}")
            return [], {'input': 0, 'output': 0}
    
    def _extract_json_from_response(self, content: str) -> List[Dict]:
        """ä»LLMå“åº”ä¸­æå–JSON"""
        json_match = re.search(r'```(?:json)?\s*([\s\S]*?)\s*```', content)
        if json_match:
            json_str = json_match.group(1)
        else:
            json_str = content
        
        try:
            data = json.loads(json_str)
            if isinstance(data, list):
                return self._normalize_models(data)
            return []
        except json.JSONDecodeError:
            return []
    
    def _normalize_models(self, models: List[Dict]) -> List[Dict]:
        """æ ‡å‡†åŒ–æ¨¡å‹æ•°æ®æ ¼å¼"""
        normalized = []
        for m in models:
            if not isinstance(m, dict) or not m.get('model_id'):
                continue
            
            model_id = str(m['model_id']).lower().strip()
            
            # å¤„ç†tiered_pricing -> è½¬æ¢ä¸ºæ ‡å‡†pricingæ ¼å¼
            pricing = []
            if m.get('tiered_pricing'):
                for tier in m['tiered_pricing']:
                    if isinstance(tier, dict):
                        pricing.append({
                            "region": "cn-beijing",
                            "token_range": tier.get('token_range', ''),
                            "input_price": {
                                "price": tier.get('input_price', 0),
                                "unit": "åƒToken",
                                "unit_quantity": 1000
                            },
                            "output_price": {
                                "price": tier.get('output_price', 0),
                                "unit": "åƒToken",
                                "unit_quantity": 1000
                            }
                        })
            
            normalized.append({
                "model_id": model_id,
                "model_name": str(m.get('model_name', model_id)),
                "vendor": m.get('vendor', 'aliyun'),
                "category": m.get('category', 'text_generation'),
                "specs": m.get('specs') if isinstance(m.get('specs'), dict) else None,
                "pricing": pricing,
                "has_tiered_pricing": len(pricing) > 1,
                "status": "active"
            })
        
        return normalized
    
    def _deduplicate_models(self, models: List[Dict]) -> List[Dict]:
        """å»é‡ï¼Œä¿ç•™ä¿¡æ¯æœ€å®Œæ•´çš„è®°å½•"""
        seen = {}
        for m in models:
            mid = m['model_id']
            if mid not in seen:
                seen[mid] = m
            else:
                existing = seen[mid]
                # ä¿ç•™pricingæ›´å®Œæ•´çš„
                if len(m.get('pricing', [])) > len(existing.get('pricing', [])):
                    seen[mid] = m
        
        return list(seen.values())


def main():
    parser = LLMModelParserV2()
    result = parser.parse_html_file("bailian_page.html")
    
    # æ˜¾ç¤ºæœ‰é˜¶æ¢¯è®¡ä»·çš„æ¨¡å‹
    tiered_models = [m for m in result['models'] if m.get('has_tiered_pricing')]
    print(f"\nğŸ“Š æœ‰é˜¶æ¢¯è®¡ä»·çš„æ¨¡å‹: {len(tiered_models)}")
    for m in tiered_models[:5]:
        print(f"   - {m['model_id']}: {len(m.get('pricing', []))} ä¸ªä»·æ ¼æ®µ")
        for p in m.get('pricing', [])[:2]:
            print(f"     {p.get('token_range')}: è¾“å…¥={p.get('input_price', {}).get('price')}, è¾“å‡º={p.get('output_price', {}).get('price')}")


if __name__ == "__main__":
    main()
